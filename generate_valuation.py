import requests
import pandas as pd
import numpy as np
import yfinance as yf
import json
import os
import time
from datetime import datetime

# --- 1. é…ç½® ---
FMP_API_KEY = "F9dROu64FwpDqETGsu1relweBEoTcpID"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_DIR = os.path.join(BASE_DIR, "data")
CACHE_BASE_DIR = os.path.join(OUTPUT_DIR, "fmp_cache") # ç·©å­˜ä¸»ç›®éŒ„
DOW_30 = ["AMZN", "AAPL", "GOOGL", "MSFT", "WMT"] 

WINDOWS = {"1Y": 252, "2Y": 504, "3Y": 756, "5Y": 1260}
QUARTERS = ['q1', 'q2', 'q3', 'q4']

# --- 2. æŠ½å–å±¤ (Extract Layer) ---
def get_fmp_fragmented(endpoint, ticker):
    """
    [Data Engineering Logic]: 
    è‡ªå‹•å»ºç«‹å°æ‡‰ ticker çš„å­è³‡æ–™å¤¾ (ä¾‹å¦‚ fmp_cache/AMZN/)ã€‚
    """
    combined = []
    
    # å»ºç«‹ ticker å°ˆå±¬è·¯å¾‘ï¼šdata/fmp_cache/{ticker}
    ticker_cache_dir = os.path.join(CACHE_BASE_DIR, ticker.upper())
    os.makedirs(ticker_cache_dir, exist_ok=True) # è‡ªå‹•å»ºç«‹å¤šå±¤ç›®éŒ„

    for q in QUARTERS:
        # æ–‡ä»¶å‘½åä¿æŒ endpoint å€åˆ†
        cache_path = os.path.join(ticker_cache_dir, f"{endpoint}_{q}.json")
        
        # ç·©å­˜æª¢æŸ¥ (7å¤©æœ‰æ•ˆæœŸ)
        if os.path.exists(cache_path) and (time.time() - os.path.getmtime(cache_path)) < (7 * 86400):
            with open(cache_path, 'r') as f:
                combined.extend(json.load(f))
            continue

        url = f"https://financialmodelingprep.com/stable/{endpoint}/?symbol={ticker}&period={q}&apikey={FMP_API_KEY}"
        
        try:
            print(f"  ğŸš€ [API Call] Fetching {ticker} {endpoint} {q}...")
            res = requests.get(url).json()
            if isinstance(res, list):
                with open(cache_path, 'w') as f:
                    json.dump(res, f, indent=4) # å¢åŠ  indent æ–¹ä¾¿ DE é€²è¡Œ Debug
                combined.extend(res)
            time.sleep(0.2)
        except Exception as e:
            print(f"  âŒ [Error] Failed to fetch {endpoint} {q}: {e}")
            
    return combined

# --- 3. è½‰æ›å±¤ (Transform Layer) ---
def build_quarterly_ttm(ticker):
    inc_list = get_fmp_fragmented("income-statement", ticker)
    cf_list = get_fmp_fragmented("cash-flow-statement", ticker)
    ev_list = get_fmp_fragmented("enterprise-values", ticker)
    
    if not all([inc_list, cf_list, ev_list]): return None, None

    df_inc = pd.DataFrame(inc_list).drop_duplicates('date').set_index('date').sort_index()
    df_cf = pd.DataFrame(cf_list).drop_duplicates('date').set_index('date').sort_index()
    df_ev = pd.DataFrame(ev_list).drop_duplicates('date').set_index('date').sort_index()

    for df in [df_inc, df_cf, df_ev]:
        df.index = pd.to_datetime(df.index).tz_localize(None)

    # æ•¸æ“šåˆä½µèˆ‡è¨ˆç®— TTM
    df_inc['eps_ttm'] = df_inc['eps'].rolling(window=4).sum()
    df_main = pd.concat([df_inc[['eps_ttm']], df_cf['freeCashFlow'], df_ev['numberOfShares']], axis=1).ffill()
    df_main['fcf_ps_ttm'] = (df_main['freeCashFlow'] / df_main['numberOfShares']).rolling(window=4).sum()

    return df_main[['eps_ttm']].dropna(), df_main[['fcf_ps_ttm']].dropna()

# --- 3. æ ¸å¿ƒä¼°å€¼é‚è¼¯ (Senior Analyst Hybrid Version) ---
def calculate_bands(ticker, prices_df, metrics_df, col_name):
    # æ—¥æœŸæ¨™æº–åŒ–èˆ‡å…¨æ™‚é–“è»¸åˆä½µ
    prices_df.index = pd.to_datetime(prices_df.index).tz_localize(None).normalize()
    metrics_df.index = pd.to_datetime(metrics_df.index).tz_localize(None).normalize()
    
    all_dates = prices_df.index.union(metrics_df.index).sort_values()
    df = pd.DataFrame(index=all_dates).join(prices_df)
    df['metric_raw'] = metrics_df[col_name]

    # è™•ç†æ‹†åˆ†èª¿æ•´å› å­ (å³ä½¿ yfinance èª¿æ•´éï¼Œæ­¤è™•ä»ä¿ç•™é‚è¼¯ä»¥é˜²è¬ä¸€)
    df['adj_ratio'] = (df['Adj Close'] / df['Close'].replace(0, np.nan)).ffill().bfill()
    df['metric_adj'] = df['metric_raw'] * df['adj_ratio']
    df['metric_final'] = df['metric_adj'].interpolate(method='time').ffill().bfill()

    # è¨ˆç®—å€æ•¸ï¼šæ’é™¤è² å€¼
    df['multiple'] = df['Adj Close'] / df['metric_final']
    df.loc[df['metric_final'] <= 0, 'multiple'] = np.nan

    # --- ç­–ç•¥é¸æ“‡é‚è¼¯ ---
    # å¦‚æœè² å€¼æˆ–æ¥µç«¯å€¼æ¯”ä¾‹éé«˜ (å¦‚ AMZN)ï¼Œè‡ªå‹•åˆ‡æ›è‡³ Median
    null_ratio = df['multiple'].isna().mean()
    use_median = True if (ticker == "AMZN" or null_ratio > 0.1) else False
    
    # å€æ•¸å‰ªæ (Winsorization)
    upper_limit = 150 if 'eps' in col_name else 120
    df['multiple'] = df['multiple'].clip(0, upper_limit)

    results = {}
    avgs = {}

    for label, window in WINDOWS.items():
        # Hybrid æ»¾å‹•è¨ˆç®—
        if use_median:
            m_col = df['multiple'].rolling(window=window, min_periods=60).median()
        else:
            m_col = df['multiple'].rolling(window=window, min_periods=60).mean()
            
        s_col = df['multiple'].rolling(window=window, min_periods=60).std().fillna(0)
        
        # é˜²æ­¢æ¨™æº–å·®éå¤§å°è‡´ Band ç‚¸é–‹ (ä¸Šé™è¨­ç‚ºå‡å€¼çš„ 60%)
        s_col = s_col.clip(upper=m_col * 0.6)

        res = pd.DataFrame(index=df.index)
        res['mean'] = m_col * df['metric_final']
        res['up1'] = (m_col + s_col) * df['metric_final']
        res['up2'] = (m_col + 2 * s_col) * df['metric_final']
        res['down1'] = (m_col - s_col) * df['metric_final']
        res['down2'] = (m_col - 2 * s_col) * df['metric_final']

        results[label] = res.loc[prices_df.index].clip(lower=0).ffill().round(2)
        
        last_val = m_col.dropna().iloc[-1] if not m_col.dropna().empty else 0
        avgs[label] = round(float(last_val), 2)

    for col in ['mean', 'up1', 'up2', 'down1', 'down2']:
        res.loc[df['metric_final'] <= 0, col] = 0

    return results, avgs

def test_amzn_valuation_logic():
    ticker = "AMZN"
    print(f"ğŸ§ª Starting Diagnostic Test for {ticker}...")

    # 1. ç²å–æ•¸æ“š
    hist = yf.Ticker(ticker).history(period="7y", auto_adjust=False)
    prices_df = hist[['Close', 'Adj Close']].copy()
    
    eps_ttm, fcf_ttm = build_quarterly_ttm(ticker)
    
    if fcf_ttm is None:
        print("âŒ Test Failed: Could not fetch FCF data.")
        return

    # 2. åŸ·è¡Œè¨ˆç®— (é€™è£¡æˆ‘å€‘æœƒæˆªå– calculate_bands çš„ä¸­é–“ç‹€æ…‹)
    # æˆ‘å€‘ç‰¹åˆ¥é—œæ³¨ P/FCFï¼Œå› ç‚ºé‚£æ˜¯ AMZN ç”¢ç”Ÿã€Œé¼“åŒ…ã€çš„åœ°æ–¹
    pe_res, pe_avgs = calculate_bands(ticker, prices_df, eps_ttm, 'eps_ttm')
    fcf_res, fcf_avgs = calculate_bands(ticker, prices_df, fcf_ttm, 'fcf_ps_ttm')

    # ---------------------------------------------------------
    # é æœŸæª¢æŸ¥ 1: è² å€¼ FCF è™•ç†
    # ---------------------------------------------------------
    # æ‰¾åˆ° 2022 å¹´ FCF ç‚ºè² çš„æ™‚æœŸ
    negative_fcf_period = fcf_ttm[fcf_ttm['fcf_ps_ttm'] < 0]
    if not negative_fcf_period.empty:
        test_date = negative_fcf_period.index[0]
        # æª¢æŸ¥è©²æ—¥æœŸçš„ä¼°å€¼ç·šæ˜¯å¦ç‚º 0 (å› ç‚º clip(lower=0))
        val_at_neg = fcf_res["2Y"].loc[test_date]
        if val_at_neg['mean'] == 0:
            print(f"âœ… Pass: Negative FCF at {test_date.date()} resulted in 0 valuation band.")
        else:
            print(f"âŒ Fail: Valuation band not grounded during negative FCF.")
    else:
        print("âš ï¸ Info: No negative FCF found in current cache for testing.")

    # ---------------------------------------------------------
    # é æœŸæª¢æŸ¥ 2: ç­–ç•¥è‡ªå‹•åˆ‡æ› (AMZN æ‡‰ä½¿ç”¨ Median)
    # ---------------------------------------------------------
    # é©—è­‰å¹³å‡å€æ•¸æ˜¯å¦åœ¨åˆç†ç¯„åœ (AMZN æ­·å² FCF ä¸­ä½æ•¸ç´„åœ¨ 30-70 ä¹‹é–“)
    avg_fcf_5y = fcf_avgs["5Y"]
    if 20 < avg_fcf_5y < 120:
        print(f"âœ… Pass: 5Y Average P/FCF ({avg_fcf_5y}) is within realistic analyst bounds (20-120).")
    else:
        print(f"âŒ Fail: 5Y Average P/FCF ({avg_fcf_5y}) is unrealistic. Clipping or Median logic might have failed.")

    # ---------------------------------------------------------
    # é æœŸæª¢æŸ¥ 3: Band çš„ç©©å®šæ€§ (æª¢æŸ¥æ¨™æº–å·®)
    # ---------------------------------------------------------
    # æª¢æŸ¥ 2023 å¹´ï¼ˆFCF æ¢å¾©æœŸï¼‰çš„ Band å¯¬åº¦æ˜¯å¦åˆç†
    # å¦‚æœ Band ç‚¸é–‹ï¼Œup2 æœƒé é«˜æ–¼ mean
    sample_date = pd.to_datetime("2023-12-01")
    if sample_date in fcf_res["2Y"].index:
        row = fcf_res["2Y"].loc[sample_date]
        ratio = row['up2'] / row['mean'] if row['mean'] > 0 else 0
        if ratio < 2.5: # ç¶“é©—æ³•å‰‡ï¼šup2 ä¸æ‡‰è¶…é mean çš„ 2.5 å€
            print(f"âœ… Pass: Valuation bands are stable at {sample_date.date()}. (Spread ratio: {ratio:.2f})")
        else:
            print(f"âŒ Fail: Valuation bands are too wide at {sample_date.date()}. (Spread ratio: {ratio:.2f})")

    print("\nâœ¨ Diagnostic Completed.")

# --- 5. ä¸»ç¨‹åº ---
def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # å‘¼å« Debug
    ## test_amzn_valuation_logic()

    for ticker in DOW_30:
        print(f"\nğŸ—ï¸  Pipeline Starting: {ticker}")
        prices = yf.Ticker(ticker).history(period="8y", auto_adjust=False)
        prices.index = prices.index.tz_localize(None)

        prices_df = prices[['Close', 'Adj Close']].copy()

        eps_ttm, fcf_ttm = build_quarterly_ttm(ticker)
        if eps_ttm is None: continue

        pe_res, pe_avgs = calculate_bands(ticker, prices_df, eps_ttm, 'eps_ttm')
        fcf_res, fcf_avgs = calculate_bands(ticker, prices_df, fcf_ttm, 'fcf_ps_ttm')

        history = []

        for date, row in prices[prices.index >= '2021-01-01'].iterrows():
            if date not in pe_res["1Y"].index: continue
            history.append({
                "date": date.strftime("%Y-%m-%d"),
                "price": round(float(row['Adj Close']), 2),
                "valuation": {
                    lb: {
                        "pe": pe_res[lb].loc[date].round(2).to_dict(),
                        "fcf": fcf_res[lb].loc[date].round(2).to_dict()
                    } for lb in WINDOWS
                }
            })
        # --- æ›´æ–° JSON çµæ§‹ï¼ŒåŠ å…¥ last_updated ---
        output_data = {
            "ticker": ticker.upper(), 
            "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),  # åŠ å…¥é€™è¡Œ
            "averages": {
                "pe": pe_avgs, 
                "fcf": fcf_avgs
            }, 
            "data": history
        }

        # æœ€å¾Œçµæœä¹Ÿå­˜å…¥ ticker è³‡æ–™å¤¾
        final_dir = os.path.join(OUTPUT_DIR, "results", ticker.upper())
        os.makedirs(final_dir, exist_ok=True)
        
        with open(os.path.join(final_dir, "valuation_summary.json"), "w") as f:
            json.dump(output_data, f, indent=4)
        print(f"âœ¨ [Success] {ticker} pipeline execution completed. Folder: {final_dir} {len(history)} points generated.")

if __name__ == "__main__":
    main()