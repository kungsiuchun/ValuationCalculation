import requests
import pandas as pd
import numpy as np
import yfinance as yf
import json
import os
import time
from datetime import datetime

FMP_API_KEY = "F9dROu64FwpDqETGsu1relweBEoTcpID"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_DIR = os.path.join(BASE_DIR, "data")

DOW_30 = ["AAPL"] 

def get_financials(ticker):
    print(f"  [1/3] Fetching Stable FMP Income Statement for {ticker}...")
    # å®Œå…¨ä¿ç•™ä½ çš„åŸå§‹ URL
    url = f"https://financialmodelingprep.com/stable/income-statement/?symbol={ticker}&apikey={FMP_API_KEY}"

    try:
        response = requests.get(url)
        inc_data = response.json()

        if not inc_data or "Error Message" in str(inc_data):
            print(f"  âŒ FMP API Error: {inc_data}")
            return None

        df_inc = pd.DataFrame(inc_data)
        required_cols = ['date', 'eps'] # æ ¸å¿ƒéœ€è¦é€™å…©å€‹
        df_inc = df_inc[required_cols].copy()
        df_inc['date'] = pd.to_datetime(df_inc['date']).dt.tz_localize(None)
        
        df_inc = df_inc.set_index('date').sort_index()
        print(f"  âœ… Financials found: {len(df_inc)} rows")
        return df_inc
        
    except Exception as e:
        print(f"  âŒ Error fetching financials: {e}")
        return None

def process_pipeline():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    for ticker in DOW_30:
        print(f"\nğŸš€ Starting Pipeline for {ticker}...")
        
        financials = get_financials(ticker)
        if financials is None or financials.empty: 
            print("  âŒ No financials found, skipping...")
            continue

        print(f"  [2/3] Fetching yfinance prices...")
        stock = yf.Ticker(ticker)
        price_df = stock.history(period="10y")[['Close']]
        price_df.index = price_df.index.tz_localize(None)

        print(f"  [3/3] Transforming Data (Safe Interpolation)...")
        
        # --- æ ¸å¿ƒé‚è¼¯ä¿®å¾©ï¼šä½¿ç”¨ Concat ç¢ºä¿é€±æœ«çš„è²¡å ±ä¹Ÿä¸æœƒä¸Ÿå¤± ---
        # å‰µå»ºä¸€å€‹åŒ…å«æ‰€æœ‰æ—¥æœŸçš„ DataFrame
        combined = pd.concat([price_df, financials], axis=0).sort_index()
        
        # åœ¨è¯é›†æ™‚é–“è»¸ä¸Šæ’å€¼ (ç·šæ€§æ’å€¼è®“éšæ¢¯è®Šæ›²ç·š)
        combined['eps_smooth'] = combined['eps'].interpolate(method='time')
        
        # å¡«å……é¦–å°¾å¯èƒ½çš„ç©ºå€¼
        combined['eps_smooth'] = combined['eps_smooth'].ffill().bfill()
        
        # ç¾åœ¨åªä¿ç•™æœ‰è‚¡åƒ¹çš„æ—¥æœŸ (äº¤æ˜“æ—¥)
        merged = combined.dropna(subset=['Close']).copy()
        
        # è¨ˆç®—æ¯æ—¥ PE
        merged['daily_pe'] = merged['Close'] / merged['eps_smooth']
        
        # è¨ˆç®—æ»¾å‹•çµ±è¨ˆ (min_periods=1 ç¢ºä¿ä¸æœƒ NaN)
        window = 504
        merged['rolling_mean'] = merged['daily_pe'].rolling(window=window, min_periods=1).mean()
        merged['rolling_std'] = merged['daily_pe'].rolling(window=window, min_periods=1).std().fillna(0)

        # ç”Ÿæˆé€šé“åƒ¹æ ¼
        merged['band_mean'] = merged['rolling_mean'] * merged['eps_smooth']
        merged['band_up2'] = (merged['rolling_mean'] + 2 * merged['rolling_std']) * merged['eps_smooth']
        merged['band_down2'] = (merged['rolling_mean'] - 2 * merged['rolling_std']) * merged['eps_smooth']

        # --- å°è£ JSON ---
        final_df = merged[merged.index >= '2021-01-01']
        
        history = []
        for date, row in final_df.iterrows():
            # ç¢ºä¿å¯«å…¥ JSON å‰è½‰æ›ç‚ºåŸç”Ÿçš„ Python floatï¼Œé¿å… NaN
            history.append({
                "date": date.strftime("%Y-%m-%d"),
                "price": float(round(row['Close'], 2)),
                "bands": {
                    "mean": float(round(row['band_mean'], 2)),
                    "up2": float(round(row['band_up2'], 2)),
                    "down2": float(round(row['band_down2'], 2))
                }
            })

        final_output = {
            "ticker": ticker,
            "last_updated": datetime.now().strftime("%Y-%m-%d"),
            "summary": {
                "rolling_avg_pe": float(round(merged['rolling_mean'].iloc[-1], 2)),
                "current_pe": float(round(merged['daily_pe'].iloc[-1], 2))
            },
            "data": history
        }

        file_path = os.path.join(OUTPUT_DIR, f"{ticker}.json")
        with open(file_path, "w") as f:
            json.dump(final_output, f)
        
        print(f"  ğŸ’¾ SUCCESS: {ticker}.json generated with {len(history)} data points.")
        time.sleep(1)

if __name__ == "__main__":
    process_pipeline()